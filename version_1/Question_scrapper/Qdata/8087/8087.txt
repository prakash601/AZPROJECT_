For a sequence of integers
[x1,x2,…,xk]
, let's define its decomposition as follows:
Process the sequence from the first element to the last one, maintaining the list of its subsequences. When you process the element
xi
, append it to the end of the first subsequence in the list such that the bitwise AND of its last element and
xi
is greater than
0
. If there is no such subsequence in the list, create a new subsequence with only one element
xi
and append it to the end of the list of subsequences.
For example, let's analyze the decomposition of the sequence
[1,3,2,0,1,3,2,1]
:
processing element
1
, the list of subsequences is empty. There is no subsequence to append
1
to, so we create a new subsequence
[1]
;
processing element
3
, the list of subsequences is
[[1]]
. Since the bitwise AND of
3
and
1
is
1
, the element is appended to the first subsequence;
processing element
2
, the list of subsequences is
[[1,3]]
. Since the bitwise AND of
2
and
3
is
2
, the element is appended to the first subsequence;
processing element
0
, the list of subsequences is
[[1,3,2]]
. There is no subsequence to append
0
to, so we create a new subsequence
[0]
;
processing element
1
, the list of subsequences is
[[1,3,2],[0]]
. There is no subsequence to append
1
to, so we create a new subsequence
[1]
;
processing element
3
, the list of subsequences is
[[1,3,2],[0],[1]]
. Since the bitwise AND of
3
and
2
is
2
, the element is appended to the first subsequence;
processing element
2
, the list of subsequences is
[[1,3,2,3],[0],[1]]
. Since the bitwise AND of
2
and
3
is
2
, the element is appended to the first subsequence;
processing element
1
, the list of subsequences is
[[1,3,2,3,2],[0],[1]]
. The element
1
cannot be appended to any of the first two subsequences, but can be appended to the third one.
The resulting list of subsequences is
[[1,3,2,3,2],[0],[1,1]]
.
Let
f([x1,x2,…,xk])
be the number of subsequences the sequence
[x1,x2,…,xk]
is decomposed into.
Now, for the problem itself.
You are given a sequence
[a1,a2,…,an]
, where each element is an integer from
0
to
3
. Let
a[i..j]
be the sequence
[ai,ai+1,…,aj]
. You have to calculate
n
∑
i=1
n
∑
j=i
f(a[i..j])
.
Input
The first line contains one integer
n
(
1≤n≤3⋅105
).
The second line contains
n
integers
a1,a2,…,an
(
0≤ai≤3
).
Output
Print one integer, which should be equal to
n
∑
i=1
n
∑
j=i
f(a[i..j])
.
Examples
input
Copy
8
1 3 2 0 1 3 2 1
output
Copy
71
input
Copy
5
0 0 0 0 0
output
Copy
35